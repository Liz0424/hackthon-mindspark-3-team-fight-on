{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqTDq0H-XF7u",
        "outputId": "2fd6373e-73a8-41d6-8276-36ab5e8bf678"
      },
      "id": "wqTDq0H-XF7u",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "2e7a1db4",
      "metadata": {
        "id": "2e7a1db4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dropout, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from imutils.face_utils import FaceAligner\n",
        "from imutils.face_utils import rect_to_bb\n",
        "import imutils\n",
        "import dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "3d9911b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d9911b3",
        "outputId": "bdca19cf-ccc4-4cdf-c357-dfb684c93e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1452\n",
            "1452\n"
          ]
        }
      ],
      "source": [
        "data = np.load('/content/drive/MyDrive/Colab Notebooks/train/driver_drowsiness_detection/dataset_compressed.npz', allow_pickle=True)\n",
        "X = data['arr_0']\n",
        "Y = data['arr_1']\n",
        "\n",
        "X = list(X)\n",
        "Y = list(Y)\n",
        "print(len(X))\n",
        "print(len(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "vPNT2p2LbSMN"
      },
      "id": "vPNT2p2LbSMN"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1807ebc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1807ebc9",
        "outputId": "a72be361-cc3b-4107-dd7f-64b78a24ceb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1452\n",
            "(32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(X)):\n",
        "    img = X[i]\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    X[i] = img\n",
        "    \n",
        "print(len(X))\n",
        "print(X[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7a3310dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a3310dd",
        "outputId": "d72b3cc0-0801-4901-c445-44faf50250f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1452,)\n",
            "0\n",
            "{0, 1}\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "Y = label_encoder.fit_transform(Y)\n",
        "print(Y.shape)\n",
        "print(Y[0])\n",
        "print(set(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "11ac7de4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ac7de4",
        "outputId": "518f06f0-f8f7-415e-866f-8bf1e9fdcf65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1452, 32, 32, 3)\n",
            "(1452,)\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "c6b3179f",
      "metadata": {
        "id": "c6b3179f"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "073d0a65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073d0a65",
        "outputId": "8fef4473-08aa-43ec-98b7-fb598e159803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1161, 32, 32, 3)\n",
            "(1161,)\n",
            "(291, 32, 32, 3)\n",
            "(291,)\n",
            "(1161, 32, 32, 3)\n",
            "(1161, 2)\n",
            "(291, 32, 32, 3)\n",
            "(291, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "85de772d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "85de772d",
        "outputId": "5214ed38-97f6-43f9-c878-92104fb0a851"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "figure1 = plt.figure(figsize=(5, 5))\n",
        "idx_closed = np.where(Y==0)\n",
        "img_closed = X[idx_closed[0][0]]\n",
        "plt.imshow(img_closed)\n",
        "plt.title('Image of Closed Eye representing Driver is sleeping')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "figure2 = plt.figure(figsize=(5, 5))\n",
        "idx_open = np.where(Y==1)\n",
        "img_open = X[idx_open[0][0]]\n",
        "plt.imshow(img_open)\n",
        "plt.title('Image of Open Eye representing Driver is not sleeping')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "cb0dadfe",
      "metadata": {
        "id": "cb0dadfe"
      },
      "outputs": [],
      "source": [
        "def driver_drowsiness_detection_model(input_shape=(32, 32, 3)):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv1', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv2', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1, 1), name='conv5', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1, 1), name='conv6', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1, 1), name='conv7', activation='relu', \n",
        "                     kernel_initializer=glorot_uniform(seed=0)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
        "    \n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc1'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc2'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax', kernel_initializer=glorot_uniform(seed=0), name='fc3'))\n",
        "    \n",
        "    optimizer = Adam(0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "9885ef31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9885ef31",
        "outputId": "fcca8cca-4d12-4783-a980-ae4a39a1bde4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv3 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv4 (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv5 (Conv2D)              (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 4, 4, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv6 (Conv2D)              (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 4, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv7 (Conv2D)              (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 4, 4, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " fc3 (Dense)                 (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227,554\n",
            "Trainable params: 226,786\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model= driver_drowsiness_detection_model(input_shape=(32, 32, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a0f505af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0f505af",
        "outputId": "23c56b02-b9ef-462d-c213-bed389b50ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 9s 723ms/step - loss: 1.2687 - accuracy: 0.5357 - val_loss: 0.7864 - val_accuracy: 0.5017\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 1.1035 - accuracy: 0.5444 - val_loss: 0.7440 - val_accuracy: 0.5052\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 1.0319 - accuracy: 0.5521 - val_loss: 0.7037 - val_accuracy: 0.5223\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.9958 - accuracy: 0.5573 - val_loss: 0.6689 - val_accuracy: 0.5670\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.9073 - accuracy: 0.5935 - val_loss: 0.6503 - val_accuracy: 0.6186\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 7s 768ms/step - loss: 0.9221 - accuracy: 0.5926 - val_loss: 0.6393 - val_accuracy: 0.6770\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 7s 697ms/step - loss: 0.8193 - accuracy: 0.6133 - val_loss: 0.6352 - val_accuracy: 0.7285\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.8196 - accuracy: 0.6219 - val_loss: 0.6312 - val_accuracy: 0.7595\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.8086 - accuracy: 0.6236 - val_loss: 0.6256 - val_accuracy: 0.7732\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.7151 - accuracy: 0.6537 - val_loss: 0.6188 - val_accuracy: 0.7663\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 7s 703ms/step - loss: 0.6841 - accuracy: 0.6632 - val_loss: 0.6138 - val_accuracy: 0.7457\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 7s 701ms/step - loss: 0.7301 - accuracy: 0.6770 - val_loss: 0.6048 - val_accuracy: 0.7457\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.6560 - accuracy: 0.6848 - val_loss: 0.5920 - val_accuracy: 0.7491\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.7193 - accuracy: 0.6641 - val_loss: 0.5759 - val_accuracy: 0.7629\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.6338 - accuracy: 0.7063 - val_loss: 0.5566 - val_accuracy: 0.7732\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.5852 - accuracy: 0.7183 - val_loss: 0.5356 - val_accuracy: 0.7766\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.5631 - accuracy: 0.7218 - val_loss: 0.5104 - val_accuracy: 0.7904\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.5519 - accuracy: 0.7442 - val_loss: 0.4871 - val_accuracy: 0.8110\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.5923 - accuracy: 0.7562 - val_loss: 0.4574 - val_accuracy: 0.8076\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.5374 - accuracy: 0.7545 - val_loss: 0.4278 - val_accuracy: 0.8282\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.5189 - accuracy: 0.7769 - val_loss: 0.4048 - val_accuracy: 0.8522\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 7s 692ms/step - loss: 0.5163 - accuracy: 0.7795 - val_loss: 0.3861 - val_accuracy: 0.8591\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.5036 - accuracy: 0.7761 - val_loss: 0.3633 - val_accuracy: 0.8694\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.4693 - accuracy: 0.7916 - val_loss: 0.3384 - val_accuracy: 0.8832\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 7s 781ms/step - loss: 0.5073 - accuracy: 0.8036 - val_loss: 0.3225 - val_accuracy: 0.8866\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.4613 - accuracy: 0.8045 - val_loss: 0.3115 - val_accuracy: 0.8935\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 7s 681ms/step - loss: 0.4375 - accuracy: 0.8122 - val_loss: 0.2983 - val_accuracy: 0.8969\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 7s 680ms/step - loss: 0.4088 - accuracy: 0.8432 - val_loss: 0.2840 - val_accuracy: 0.8969\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.4307 - accuracy: 0.8415 - val_loss: 0.2719 - val_accuracy: 0.8935\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.4210 - accuracy: 0.8407 - val_loss: 0.2552 - val_accuracy: 0.8900\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.4359 - accuracy: 0.8484 - val_loss: 0.2410 - val_accuracy: 0.9003\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 7s 710ms/step - loss: 0.3514 - accuracy: 0.8596 - val_loss: 0.2286 - val_accuracy: 0.9038\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.3335 - accuracy: 0.8734 - val_loss: 0.2178 - val_accuracy: 0.9038\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.3496 - accuracy: 0.8553 - val_loss: 0.2083 - val_accuracy: 0.9072\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.3219 - accuracy: 0.8760 - val_loss: 0.1987 - val_accuracy: 0.9107\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.3342 - accuracy: 0.8751 - val_loss: 0.1923 - val_accuracy: 0.9141\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 7s 692ms/step - loss: 0.3177 - accuracy: 0.8777 - val_loss: 0.1840 - val_accuracy: 0.9141\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 7s 763ms/step - loss: 0.3069 - accuracy: 0.8837 - val_loss: 0.1737 - val_accuracy: 0.9313\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.2980 - accuracy: 0.8906 - val_loss: 0.1667 - val_accuracy: 0.9381\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.3141 - accuracy: 0.8803 - val_loss: 0.1611 - val_accuracy: 0.9313\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.2988 - accuracy: 0.8889 - val_loss: 0.1578 - val_accuracy: 0.9347\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.2906 - accuracy: 0.8923 - val_loss: 0.1539 - val_accuracy: 0.9381\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.2710 - accuracy: 0.9053 - val_loss: 0.1474 - val_accuracy: 0.9381\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.2665 - accuracy: 0.9001 - val_loss: 0.1441 - val_accuracy: 0.9347\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.2520 - accuracy: 0.9070 - val_loss: 0.1398 - val_accuracy: 0.9347\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.2458 - accuracy: 0.9044 - val_loss: 0.1352 - val_accuracy: 0.9347\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.2424 - accuracy: 0.9104 - val_loss: 0.1324 - val_accuracy: 0.9416\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.2286 - accuracy: 0.9053 - val_loss: 0.1366 - val_accuracy: 0.9416\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 7s 760ms/step - loss: 0.2173 - accuracy: 0.9190 - val_loss: 0.1286 - val_accuracy: 0.9347\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.2409 - accuracy: 0.9078 - val_loss: 0.1218 - val_accuracy: 0.9381\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.2419 - accuracy: 0.9053 - val_loss: 0.1212 - val_accuracy: 0.9450\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.2426 - accuracy: 0.9225 - val_loss: 0.1165 - val_accuracy: 0.9588\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.2232 - accuracy: 0.9233 - val_loss: 0.1118 - val_accuracy: 0.9519\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.2188 - accuracy: 0.9190 - val_loss: 0.1088 - val_accuracy: 0.9519\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.2063 - accuracy: 0.9139 - val_loss: 0.1070 - val_accuracy: 0.9519\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.2282 - accuracy: 0.9225 - val_loss: 0.1034 - val_accuracy: 0.9588\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 7s 763ms/step - loss: 0.2208 - accuracy: 0.9294 - val_loss: 0.1011 - val_accuracy: 0.9588\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.1911 - accuracy: 0.9320 - val_loss: 0.0971 - val_accuracy: 0.9553\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.1771 - accuracy: 0.9380 - val_loss: 0.0925 - val_accuracy: 0.9588\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.1851 - accuracy: 0.9345 - val_loss: 0.0906 - val_accuracy: 0.9588\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.1712 - accuracy: 0.9440 - val_loss: 0.0927 - val_accuracy: 0.9622\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.1691 - accuracy: 0.9414 - val_loss: 0.0911 - val_accuracy: 0.9691\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.1517 - accuracy: 0.9475 - val_loss: 0.0867 - val_accuracy: 0.9691\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.1804 - accuracy: 0.9363 - val_loss: 0.0837 - val_accuracy: 0.9725\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.1678 - accuracy: 0.9449 - val_loss: 0.0844 - val_accuracy: 0.9725\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.1694 - accuracy: 0.9388 - val_loss: 0.0838 - val_accuracy: 0.9691\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.2018 - accuracy: 0.9276 - val_loss: 0.0814 - val_accuracy: 0.9622\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 7s 679ms/step - loss: 0.1564 - accuracy: 0.9449 - val_loss: 0.0797 - val_accuracy: 0.9656\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 7s 681ms/step - loss: 0.1310 - accuracy: 0.9552 - val_loss: 0.0830 - val_accuracy: 0.9656\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.1381 - accuracy: 0.9457 - val_loss: 0.0842 - val_accuracy: 0.9656\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1247 - accuracy: 0.9587 - val_loss: 0.0769 - val_accuracy: 0.9691\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 7s 779ms/step - loss: 0.1497 - accuracy: 0.9432 - val_loss: 0.0713 - val_accuracy: 0.9725\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.1299 - accuracy: 0.9466 - val_loss: 0.0678 - val_accuracy: 0.9725\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.1374 - accuracy: 0.9509 - val_loss: 0.0679 - val_accuracy: 0.9725\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.1332 - accuracy: 0.9595 - val_loss: 0.0786 - val_accuracy: 0.9622\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 7s 781ms/step - loss: 0.1277 - accuracy: 0.9483 - val_loss: 0.0811 - val_accuracy: 0.9622\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.1547 - accuracy: 0.9466 - val_loss: 0.0830 - val_accuracy: 0.9588\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.1093 - accuracy: 0.9526 - val_loss: 0.0788 - val_accuracy: 0.9553\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 7s 704ms/step - loss: 0.1457 - accuracy: 0.9535 - val_loss: 0.0751 - val_accuracy: 0.9588\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 7s 710ms/step - loss: 0.1208 - accuracy: 0.9561 - val_loss: 0.0708 - val_accuracy: 0.9691\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.1387 - accuracy: 0.9483 - val_loss: 0.0717 - val_accuracy: 0.9725\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.1133 - accuracy: 0.9638 - val_loss: 0.0688 - val_accuracy: 0.9691\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.1146 - accuracy: 0.9595 - val_loss: 0.0677 - val_accuracy: 0.9691\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.1255 - accuracy: 0.9604 - val_loss: 0.0680 - val_accuracy: 0.9759\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.1401 - accuracy: 0.9543 - val_loss: 0.0732 - val_accuracy: 0.9691\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 7s 709ms/step - loss: 0.1233 - accuracy: 0.9630 - val_loss: 0.0711 - val_accuracy: 0.9725\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 7s 783ms/step - loss: 0.0854 - accuracy: 0.9699 - val_loss: 0.0668 - val_accuracy: 0.9794\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.0900 - accuracy: 0.9716 - val_loss: 0.0628 - val_accuracy: 0.9725\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 7s 706ms/step - loss: 0.0990 - accuracy: 0.9621 - val_loss: 0.0723 - val_accuracy: 0.9691\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 7s 704ms/step - loss: 0.1152 - accuracy: 0.9561 - val_loss: 0.0661 - val_accuracy: 0.9759\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 7s 701ms/step - loss: 0.1212 - accuracy: 0.9587 - val_loss: 0.0650 - val_accuracy: 0.9794\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.1095 - accuracy: 0.9681 - val_loss: 0.0635 - val_accuracy: 0.9794\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 7s 701ms/step - loss: 0.1289 - accuracy: 0.9578 - val_loss: 0.0632 - val_accuracy: 0.9794\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 7s 705ms/step - loss: 0.1123 - accuracy: 0.9655 - val_loss: 0.0660 - val_accuracy: 0.9691\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0994 - accuracy: 0.9604 - val_loss: 0.0663 - val_accuracy: 0.9725\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 7s 697ms/step - loss: 0.1034 - accuracy: 0.9647 - val_loss: 0.0625 - val_accuracy: 0.9725\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 7s 779ms/step - loss: 0.1010 - accuracy: 0.9561 - val_loss: 0.0671 - val_accuracy: 0.9691\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.0941 - accuracy: 0.9647 - val_loss: 0.0660 - val_accuracy: 0.9691\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.1006 - accuracy: 0.9647 - val_loss: 0.0644 - val_accuracy: 0.9759\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0851 - accuracy: 0.9673 - val_loss: 0.0668 - val_accuracy: 0.9725\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.1002 - accuracy: 0.9621 - val_loss: 0.0672 - val_accuracy: 0.9725\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.1040 - accuracy: 0.9716 - val_loss: 0.0654 - val_accuracy: 0.9759\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.0899 - accuracy: 0.9673 - val_loss: 0.0653 - val_accuracy: 0.9656\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.1109 - accuracy: 0.9673 - val_loss: 0.0613 - val_accuracy: 0.9725\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0970 - accuracy: 0.9673 - val_loss: 0.0673 - val_accuracy: 0.9656\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.1109 - accuracy: 0.9569 - val_loss: 0.0608 - val_accuracy: 0.9656\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.1034 - accuracy: 0.9647 - val_loss: 0.0559 - val_accuracy: 0.9725\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0846 - accuracy: 0.9707 - val_loss: 0.0556 - val_accuracy: 0.9725\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0693 - accuracy: 0.9785 - val_loss: 0.0561 - val_accuracy: 0.9691\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.0811 - accuracy: 0.9681 - val_loss: 0.0590 - val_accuracy: 0.9691\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.0830 - accuracy: 0.9699 - val_loss: 0.0569 - val_accuracy: 0.9656\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.0585 - val_accuracy: 0.9725\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 7s 680ms/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 0.0588 - val_accuracy: 0.9691\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.0995 - accuracy: 0.9716 - val_loss: 0.0646 - val_accuracy: 0.9588\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 7s 679ms/step - loss: 0.0788 - accuracy: 0.9716 - val_loss: 0.0642 - val_accuracy: 0.9622\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 7s 754ms/step - loss: 0.0829 - accuracy: 0.9724 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.0689 - accuracy: 0.9724 - val_loss: 0.0594 - val_accuracy: 0.9691\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.0585 - val_accuracy: 0.9691\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 7s 763ms/step - loss: 0.0823 - accuracy: 0.9664 - val_loss: 0.0577 - val_accuracy: 0.9725\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 7s 682ms/step - loss: 0.0941 - accuracy: 0.9638 - val_loss: 0.0586 - val_accuracy: 0.9691\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.0638 - accuracy: 0.9785 - val_loss: 0.0575 - val_accuracy: 0.9691\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.0598 - val_accuracy: 0.9656\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.0742 - accuracy: 0.9716 - val_loss: 0.0607 - val_accuracy: 0.9656\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 7s 753ms/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 0.0616 - val_accuracy: 0.9622\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0612 - accuracy: 0.9785 - val_loss: 0.0593 - val_accuracy: 0.9691\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 7s 682ms/step - loss: 0.0540 - accuracy: 0.9793 - val_loss: 0.0599 - val_accuracy: 0.9656\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 7s 680ms/step - loss: 0.0847 - accuracy: 0.9742 - val_loss: 0.0594 - val_accuracy: 0.9656\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.0602 - accuracy: 0.9750 - val_loss: 0.0658 - val_accuracy: 0.9656\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 7s 681ms/step - loss: 0.0558 - accuracy: 0.9854 - val_loss: 0.0727 - val_accuracy: 0.9656\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.0749 - val_accuracy: 0.9656\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.0608 - accuracy: 0.9776 - val_loss: 0.0758 - val_accuracy: 0.9656\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.0628 - accuracy: 0.9767 - val_loss: 0.0732 - val_accuracy: 0.9622\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.0671 - accuracy: 0.9759 - val_loss: 0.0737 - val_accuracy: 0.9622\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.0715 - val_accuracy: 0.9622\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.0744 - val_accuracy: 0.9656\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.0691 - accuracy: 0.9759 - val_loss: 0.0624 - val_accuracy: 0.9656\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 0.0535 - val_accuracy: 0.9691\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0816 - accuracy: 0.9724 - val_loss: 0.0545 - val_accuracy: 0.9759\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 7s 763ms/step - loss: 0.0664 - accuracy: 0.9811 - val_loss: 0.0620 - val_accuracy: 0.9759\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.0586 - val_accuracy: 0.9725\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.0686 - accuracy: 0.9802 - val_loss: 0.0542 - val_accuracy: 0.9691\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0781 - accuracy: 0.9742 - val_loss: 0.0564 - val_accuracy: 0.9691\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0591 - val_accuracy: 0.9691\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 0.0642 - val_accuracy: 0.9725\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.0743 - accuracy: 0.9767 - val_loss: 0.0650 - val_accuracy: 0.9759\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 7s 689ms/step - loss: 0.0466 - accuracy: 0.9871 - val_loss: 0.0706 - val_accuracy: 0.9725\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0668 - accuracy: 0.9724 - val_loss: 0.0688 - val_accuracy: 0.9725\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 7s 687ms/step - loss: 0.0580 - accuracy: 0.9845 - val_loss: 0.0667 - val_accuracy: 0.9725\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0611 - val_accuracy: 0.9759\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 0.0565 - val_accuracy: 0.9759\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 7s 678ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 0.0533 - val_accuracy: 0.9759\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 7s 681ms/step - loss: 0.0588 - accuracy: 0.9836 - val_loss: 0.0517 - val_accuracy: 0.9759\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.0482 - accuracy: 0.9819 - val_loss: 0.0543 - val_accuracy: 0.9725\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 7s 680ms/step - loss: 0.0431 - accuracy: 0.9819 - val_loss: 0.0574 - val_accuracy: 0.9725\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 7s 681ms/step - loss: 0.0360 - accuracy: 0.9854 - val_loss: 0.0610 - val_accuracy: 0.9759\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 7s 761ms/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.0669 - val_accuracy: 0.9759\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0650 - val_accuracy: 0.9725\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 7s 680ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.0642 - val_accuracy: 0.9759\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 7s 684ms/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 0.0588 - val_accuracy: 0.9725\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.0713 - accuracy: 0.9802 - val_loss: 0.0454 - val_accuracy: 0.9794\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.0520 - accuracy: 0.9785 - val_loss: 0.0383 - val_accuracy: 0.9828\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 7s 777ms/step - loss: 0.0660 - accuracy: 0.9785 - val_loss: 0.0388 - val_accuracy: 0.9794\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 7s 776ms/step - loss: 0.0548 - accuracy: 0.9785 - val_loss: 0.0428 - val_accuracy: 0.9794\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.0412 - accuracy: 0.9862 - val_loss: 0.0448 - val_accuracy: 0.9794\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 7s 692ms/step - loss: 0.0448 - accuracy: 0.9845 - val_loss: 0.0493 - val_accuracy: 0.9759\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 7s 777ms/step - loss: 0.0733 - accuracy: 0.9724 - val_loss: 0.0431 - val_accuracy: 0.9794\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 7s 692ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.0362 - val_accuracy: 0.9897\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0397 - val_accuracy: 0.9794\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.0423 - val_accuracy: 0.9759\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.0540 - accuracy: 0.9802 - val_loss: 0.0528 - val_accuracy: 0.9759\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 7s 697ms/step - loss: 0.0465 - accuracy: 0.9819 - val_loss: 0.0673 - val_accuracy: 0.9622\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.0701 - val_accuracy: 0.9691\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.0480 - accuracy: 0.9811 - val_loss: 0.0722 - val_accuracy: 0.9691\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.0567 - val_accuracy: 0.9725\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0358 - accuracy: 0.9854 - val_loss: 0.0462 - val_accuracy: 0.9794\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 7s 695ms/step - loss: 0.0308 - accuracy: 0.9914 - val_loss: 0.0391 - val_accuracy: 0.9794\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 7s 691ms/step - loss: 0.0429 - accuracy: 0.9897 - val_loss: 0.0365 - val_accuracy: 0.9759\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 7s 705ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9759\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.0424 - val_accuracy: 0.9794\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 0.0373 - accuracy: 0.9871 - val_loss: 0.0388 - val_accuracy: 0.9828\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 0.0401 - val_accuracy: 0.9759\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0344 - accuracy: 0.9854 - val_loss: 0.0381 - val_accuracy: 0.9794\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0321 - accuracy: 0.9854 - val_loss: 0.0389 - val_accuracy: 0.9828\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 7s 699ms/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 0.0409 - val_accuracy: 0.9794\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 0.0416 - val_accuracy: 0.9794\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 7s 707ms/step - loss: 0.0304 - accuracy: 0.9922 - val_loss: 0.0411 - val_accuracy: 0.9828\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.0479 - accuracy: 0.9836 - val_loss: 0.0436 - val_accuracy: 0.9794\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.0293 - accuracy: 0.9888 - val_loss: 0.0403 - val_accuracy: 0.9794\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 0.0433 - val_accuracy: 0.9863\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 7s 696ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.0424 - val_accuracy: 0.9794\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 7s 780ms/step - loss: 0.0325 - accuracy: 0.9922 - val_loss: 0.0286 - val_accuracy: 0.9897\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 7s 703ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 0.0279 - val_accuracy: 0.9897\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 7s 708ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.0308 - val_accuracy: 0.9897\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 7s 700ms/step - loss: 0.0384 - accuracy: 0.9871 - val_loss: 0.0458 - val_accuracy: 0.9794\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 7s 771ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.0605 - val_accuracy: 0.9725\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.0648 - val_accuracy: 0.9725\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.0595 - val_accuracy: 0.9794\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 7s 778ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 0.0565 - val_accuracy: 0.9794\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 7s 703ms/step - loss: 0.0350 - accuracy: 0.9854 - val_loss: 0.0512 - val_accuracy: 0.9794\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 7s 706ms/step - loss: 0.0291 - accuracy: 0.9914 - val_loss: 0.0496 - val_accuracy: 0.9759\n"
          ]
        }
      ],
      "source": [
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "hist = model.fit(aug.flow(X_train, Y_train, batch_size=128), batch_size=128, epochs=200, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e00b4da",
      "metadata": {
        "id": "0e00b4da"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(10, 10))\n",
        "plt.plot(hist.history['accuracy'], label='Train_accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label='Test_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "figure2 = plt.figure(figsize=(10, 10))\n",
        "plt.plot(hist.history['loss'], label='Train_loss')\n",
        "plt.plot(hist.history['val_loss'], label='Test_loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89894ac1",
      "metadata": {
        "id": "89894ac1"
      },
      "outputs": [],
      "source": [
        "pred = model.evaluate(X_test, Y_test)\n",
        "print(f'Test Set Accuracy: {pred[1]}')\n",
        "print(f'Test Set Loss: {pred[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56b7472",
      "metadata": {
        "id": "e56b7472"
      },
      "outputs": [],
      "source": [
        "ypred = model.predict(X_test)\n",
        "ypred = np.argmax(ypred, axis=1)\n",
        "Y_test_pred = np.argmax(Y_test, axis=1)\n",
        "print(classification_report(Y_test_pred, ypred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3006ee4b",
      "metadata": {
        "id": "3006ee4b"
      },
      "outputs": [],
      "source": [
        "matrix = confusion_matrix(Y_test_pred, ypred)\n",
        "df_cm = pd.DataFrame(matrix, index=[0, 1], columns=[0, 1])\n",
        "figure = plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b66d293",
      "metadata": {
        "id": "5b66d293"
      },
      "outputs": [],
      "source": [
        "model.save('Driver_Drowsiness_Detection.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Closed', 'Open']\n",
        "img_closed1 = cv2.imread('driver_drowsiness_detection/closed_eye.jpg')\n",
        "img_closed2 = cv2.imread('driver_drowsiness_detection/closed_eye2.jpg')\n",
        "img_open1 = cv2.imread('driver_drowsiness_detection/open_eye.jpg')\n",
        "img_open2 = cv2.imread('driver_drowsiness_detection/open_eye2.jpg')\n",
        "\n",
        "img_closed1 = cv2.resize(img_closed1, (32, 32))\n",
        "img_closed2 = cv2.resize(img_closed2, (32, 32))\n",
        "img_open1 = cv2.resize(img_open1, (32, 32))\n",
        "img_open2 = cv2.resize(img_open2, (32, 32))\n",
        "\n",
        "img_closed1 = np.array(img_closed1)\n",
        "img_closed2 = np.array(img_closed2)\n",
        "img_open1 = np.array(img_open1)\n",
        "img_open2 = np.array(img_open2)\n",
        "\n",
        "img_closed1 = np.expand_dims(img_closed1, axis=0)\n",
        "img_closed2 = np.expand_dims(img_closed2, axis=0)\n",
        "img_open1 = np.expand_dims(img_open1, axis=0)\n",
        "img_open2 = np.expand_dims(img_open2, axis=0)"
      ],
      "metadata": {
        "id": "tV3hXmNyYJgh"
      },
      "id": "tV3hXmNyYJgh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_closed1 = model.predict(img_closed1)\n",
        "ypred_closed2 = model.predict(img_closed2)\n",
        "ypred_open1 = model.predict(img_open1)\n",
        "ypred_open2 = model.predict(img_open2)"
      ],
      "metadata": {
        "id": "49ltfFoQYKpx"
      },
      "id": "49ltfFoQYKpx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(2, 2))\n",
        "img_closed1 = np.squeeze(img_closed1, axis=0)\n",
        "plt.imshow(img_closed1)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction by the model: {labels[np.argmax(ypred_closed1[0], axis=0)]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CofYdS0nYQQL"
      },
      "id": "CofYdS0nYQQL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(2, 2))\n",
        "img_closed2 = np.squeeze(img_closed2, axis=0)\n",
        "plt.imshow(img_closed2)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction by the model: {labels[np.argmax(ypred_closed2[0], axis=0)]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HCB8j3FPYUGh"
      },
      "id": "HCB8j3FPYUGh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(2, 2))\n",
        "img_open1 = np.squeeze(img_open1, axis=0)\n",
        "plt.imshow(img_open1)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction by the model: {labels[np.argmax(ypred_open1[0], axis=0)]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CIAkR2g4YVq8"
      },
      "id": "CIAkR2g4YVq8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(2, 2))\n",
        "img_open2 = np.squeeze(img_open2, axis=0)\n",
        "plt.imshow(img_open2)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction by the model: {labels[np.argmax(ypred_open2[0], axis=0)]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GMGCZflXYa60"
      },
      "id": "GMGCZflXYa60",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_face_detection_pipeline(input_image_path):\n",
        "    face_cascade = cv2.CascadeClassifier('driver_drowsiness_detection/haarcascade_frontalface_default.xml')\n",
        "    eye_cascade = cv2.CascadeClassifier('driver_drowsiness_detection/haarcascade_eye.xml')\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor('driver_drowsiness_detection/shape_predictor_68_face_landmarks.dat')\n",
        "    fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
        "    test_image = cv2.imread(input_image_path)\n",
        "    test_image = imutils.resize(test_image, width=800)\n",
        "    test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "    rects = detector(test_image_gray, 2)\n",
        "    for rect in rects:\n",
        "        (x, y, w, h) = rect_to_bb(rect)\n",
        "        faceOrig = imutils.resize(test_image[y:y+h, x:x+w], width=256)\n",
        "        faceAligned = fa.align(test_image, test_image_gray, rect)\n",
        "        faceAligned_gray = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
        "        plt.imshow(faceAligned_gray)\n",
        "        plt.axis('off')\n",
        "        plt.title('Aligned Face')\n",
        "        plt.show()\n",
        "        eyes = eye_cascade.detectMultiScale(faceAligned_gray, 1.1, 4)\n",
        "        predictions = []\n",
        "        for (ex, ey, ew, eh) in eyes:\n",
        "            eye = faceAligned[ey:ey+eh, ex:ex+ew]\n",
        "#             cv2.rectangle(test_image, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (0, 0, 255), 8)\n",
        "            eye = cv2.resize(eye, (32, 32))\n",
        "            eye = np.array(eye)\n",
        "            eye = np.expand_dims(eye, axis=0)\n",
        "            ypred = model.predict(eye)\n",
        "            ypred = np.argmax(ypred[0], axis=0)\n",
        "            predictions.append(ypred)\n",
        "        if all(i==0 for i in predictions):\n",
        "            cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 0, 255), 8)\n",
        "            cv2.putText(test_image, 'Sleeping', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
        "        else:\n",
        "            cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 255, 0), 8)\n",
        "            cv2.putText(test_image, 'Not Sleeping', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
        "    output_path = 'driver_drowsiness_detection/test_image_prediction.jpg'\n",
        "    cv2.imwrite(output_path, test_image) \n",
        "    return output_path"
      ],
      "metadata": {
        "id": "T1mf5v10gh-A"
      },
      "id": "T1mf5v10gh-A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(5, 5))\n",
        "predicted_image = cv2.imread(full_face_detection_pipeline('driver_drowsiness_detection/active_person.jpg'))\n",
        "predicted_image = cv2.cvtColor(predicted_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(predicted_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jEG2Mh88Yhyy"
      },
      "id": "jEG2Mh88Yhyy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(5, 5))\n",
        "predicted_image = cv2.imread(full_face_detection_pipeline('driver_drowsiness_detection/drowsy_person.jpg'))\n",
        "predicted_image = cv2.cvtColor(predicted_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(predicted_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_yq5mJU-YkSN"
      },
      "id": "_yq5mJU-YkSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "igure = plt.figure(figsize=(5, 5))\n",
        "predicted_image = cv2.imread(full_face_detection_pipeline('driver_drowsiness_detection/sleepy-driver.jpg'))\n",
        "predicted_image = cv2.cvtColor(predicted_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(predicted_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2kHKxFneYnRt"
      },
      "id": "2kHKxFneYnRt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!deepCC Driver_Drowsiness_Detection.h5"
      ],
      "metadata": {
        "id": "Or8Rl8FuYuhz"
      },
      "id": "Or8Rl8FuYuhz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "SHOW.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}